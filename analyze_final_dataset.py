#!/usr/bin/env python3
"""
Analyze individual participant contributions to the final dataset.
"""

import pickle
import numpy as np

def analyze_participant_contributions():
    """Analyze each participant's contribution to the dataset."""
    
    participants = ['vp01', 'vp02', 'vp03', 'vp04', 'vp05']
    
    print("=" * 60)
    print("INDIVIDUAL PARTICIPANT ANALYSIS")
    print("=" * 60)
    
    total_windows = 0
    all_labels = []
    
    for pid in participants:
        try:
            with open(f'data/processed/basic_windows/{pid}_windows.pkl', 'rb') as f:
                data = pickle.load(f)
            
            n_windows = data['n_windows']
            labels = data['ternary_labels']
            unique, counts = np.unique(labels, return_counts=True)
            
            print(f"\n{pid.upper()}:")
            print(f"  Windows: {n_windows}")
            print(f"  Label distribution:")
            label_names = {0: 'low', 1: 'moderate', 2: 'high'}
            for label, count in zip(unique, counts):
                percentage = (count / n_windows) * 100
                print(f"    {label_names[label]}: {count} ({percentage:.1f}%)")
            
            total_windows += n_windows
            all_labels.extend(labels)
            
        except Exception as e:
            print(f"\n{pid.upper()}: ERROR - {e}")
    
    print(f"\n{'='*60}")
    print("DATASET SUMMARY")
    print(f"{'='*60}")
    print(f"Total participants: {len(participants)}")
    print(f"Total windows: {total_windows}")
    print(f"Average windows per participant: {total_windows/len(participants):.1f}")
    
    # Overall label distribution
    all_labels = np.array(all_labels)
    unique, counts = np.unique(all_labels, return_counts=True)
    print(f"\nOverall label distribution:")
    label_names = {0: 'low', 1: 'moderate', 2: 'high'}
    for label, count in zip(unique, counts):
        percentage = (count / total_windows) * 100
        print(f"  {label_names[label]}: {count} windows ({percentage:.1f}%)")
    
    # Dataset quality metrics
    print(f"\n{'='*60}")
    print("DATASET QUALITY METRICS")
    print(f"{'='*60}")
    
    # Label balance (ideal is 33.33% each)
    balance_score = 1 - np.std(counts) / np.mean(counts)
    print(f"Label balance score: {balance_score:.3f} (1.0 = perfectly balanced)")
    
    # Data completeness
    expected_windows = len(participants) * 60  # Each participant should have 60
    completeness = total_windows / expected_windows
    print(f"Data completeness: {completeness:.3f} ({total_windows}/{expected_windows} windows)")
    
    # Individual participant balance
    print(f"\nParticipant-level balance:")
    balance_issues = []
    for pid in participants:
        try:
            with open(f'data/processed/basic_windows/{pid}_windows.pkl', 'rb') as f:
                data = pickle.load(f)
            labels = data['ternary_labels']
            unique, counts = np.unique(labels, return_counts=True)
            
            if len(unique) == 3:  # All 3 classes present
                std_dev = np.std(counts)
                if std_dev > 5:  # More than 5 windows difference
                    balance_issues.append(f"{pid} (std: {std_dev:.1f})")
        except:
            pass
    
    if balance_issues:
        print(f"  Participants with label imbalance: {', '.join(balance_issues)}")
    else:
        print(f"  All participants have balanced labels âœ“")
    
    print(f"\nðŸŽ¯ READY FOR MODEL TRAINING!")
    print(f"   â†’ {total_windows} high-quality EEG windows")
    print(f"   â†’ Balanced ternary pain classification")
    print(f"   â†’ 5 participants for robust cross-validation")

if __name__ == "__main__":
    analyze_participant_contributions()
